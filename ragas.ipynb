{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workshop om Ragas\n",
    "\n",
    "## Begrepsforklaringer\n",
    "##### RAG\n",
    "RAG står for Retrieval-Augmented Generation og gir generativ kunstig intelligens modeler informasjonsinnhenting muligheter. Dette betyr RAG-en hjelper generative KI ved å gi den tilgang til relevant informasjon som kan hjelpe med å svare på spørsmål fra bruker. \n",
    "Informasjonen blir på forhånd lagret omgjort til LLM-embeddings (store vektorer) og lagret i vektor-databaser. Før den generative KI-en svarer, blir brukerspørsmålet gjort om til en egen LLM-embedding og den embeddingen blir brukt til å sammenligne med de andre vektorene i vektor-databasen. Her blir ofte \"Cosine-similarity\" brukt for å finne vektorene som ligner mest. Deretter blir informasjonen som er mest relevant til spørsmålet, gitt til KI-en.\n",
    "\n",
    "### Hva er ragas?\n",
    "Ragas er et bra dokumentert (!), open-source bibliotek som lar deg evaluere LLM-applikasjoner og RAG-er. Viktig for denne evalueringen er metrics.\n",
    "\n",
    "<img src=\"metrics_mindmap.png\" alt=\"Metrics Mindmap\" width=\"500\"/>\n",
    "\n",
    "To typer metrics:\n",
    "\n",
    "##### LLM Based\n",
    "- Bruker LLM til å vurdere. \n",
    "- Non-deterministisk ved at LLM ikke alltid vil returnere det samme resultatet\n",
    "- Likevel vist seg å være mer nøyaktige og nærmere menneskelig evaluering\n",
    "\n",
    "##### Non-LLM Based\n",
    "- Bruker **ikke** LLM til å vurdere\n",
    "- Deterministiske \n",
    "- Bruker tradisjonelle metoder for å evaluere\n",
    "- Mindre nøyaktige sammenlignet med menneskelig evaluering\n",
    "\n",
    "\n",
    "To andre kategorier:\n",
    "##### Single Turn Metrics\n",
    "- Evaluerer basert på én runde med interaksjon mellom bruker og generativ KI\n",
    "\n",
    "##### Multiple Turn Metrics\n",
    "- Evalierer basert på flere runder med interaksjon mellom bruker og generativ KI\n",
    "\n",
    "\n",
    "### Hvordan evaluere med Ragas?\n",
    "For å evaluere hvor god en generativ KI trenger man 3 ting:\n",
    "- Spørsmål\n",
    "- Svar\n",
    "- Referanse/riktig svar\n",
    "\n",
    "Med dette kan man evaluere om svaret KI-en gir stemmer opp mot svaret vi forventer.\n",
    "\n",
    "For å evaluere hvor god en RAG er til å gi riktig informasjon til KI-en trenger man 4 ting:\n",
    "- Spørsmål\n",
    "- Svar\n",
    "- Referanse/riktig svar\n",
    "- Gitt kontekst/informasjon\n",
    "\n",
    "Den siste (gitt kontekst) er viktig når man skal vurdere hvor svikten i system ligger. Hvis det er gitt feil kontekst, er det RAG-en som har mislyktes. Hvis det er riktig kontekst, men feil svar, er det KI-en som har mislyktes. \n",
    "\n",
    "Under skal vi se hvordan vi kan evaluere en RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ragas in c:\\users\\jon bergland\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.13)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement ragas_metrics (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for ragas_metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install -U ragas langchain langchain_openai faiss-cpu pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sette env-variabler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"your_key\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Ragas Tutorial\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lese fil og lage vektor-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter, MarkdownTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.retrievers import ParentDocumentRetriever, EnsembleRetriever, MultiVectorRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.storage import InMemoryStore, InMemoryByteStore\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.stores import BaseStore\n",
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import LLMContextRecall, ContextEntityRecall, ContextPrecision, FactualCorrectness\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from ragas.utils import safe_nanmean\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import pandas as ps\n",
    "\n",
    "# Setter opp RAG-en\n",
    "\n",
    "# Leser dokumentene vi vil legge inn i RAG-en\n",
    "filepath = './dnd_doc.md'\n",
    "\n",
    "\n",
    "dnd_document: str = \"\"\n",
    "with open(filepath, encoding=\"utf-8\") as f:\n",
    "    dnd_document = f.read()\n",
    "\n",
    "# Gjør teksten om til en Document-klasse fra Langchain\n",
    "dnd_document = [Document(dnd_document)]\n",
    "\n",
    "# Splitter dokumentet med en tekstsplitter fra Langchain\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0) # TextSplitter\n",
    "splits = text_splitter.split_documents(dnd_document)\n",
    "\n",
    "# Lager en vektor-database retriever\n",
    "vector_retriever = FAISS.from_documents(splits, OpenAIEmbeddings()).as_retriever(\n",
    "            search_type=\"similarity_score_threshold\",\n",
    "            search_kwargs = {\n",
    "                \"k\": 2,\n",
    "                \"score_threshold\": 0.7\n",
    "                }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generere svar til spørsmålene i CSV-filen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "            model= \"gpt-4o-mini\",\n",
    "            temperature=0,\n",
    "            max_tokens=16384\n",
    "        )\n",
    "\n",
    "def convert_docs_to_strings(docs: list[Document]) -> list[str]:\n",
    "        \"\"\"Convert Objects of Document type to an list of strings\"\"\"\n",
    "        return [doc.page_content for doc in docs]\n",
    "\n",
    "def get_relevant_docs(query: str) -> list[str]:\n",
    "    return convert_docs_to_strings(vector_retriever.invoke(input=query))\n",
    "\n",
    "def generate_answer(query: str, relevant_doc: list[Document]):\n",
    "        \"\"\"Generate an answer for a given query based on the most relevant document.\"\"\"\n",
    "        prompt = f\"question: {query}\\n\\nDocuments: {relevant_doc}\"\n",
    "        messages = [\n",
    "            (\"system\", \"You are a helpful assistant that answers questions based on given documents only.\"),\n",
    "            (\"human\", prompt),\n",
    "        ]\n",
    "        ai_msg = llm.invoke(messages)\n",
    "        return ai_msg.content\n",
    "\n",
    "dataset = []\n",
    "\n",
    "df = ps.read_csv(\"./sample_questions_dnd.csv\")\n",
    "querys = df[\"question\"].tolist()\n",
    "responses = df[\"answer\"].tolist()\n",
    "\n",
    "token_use = 0\n",
    "\n",
    "for query, reference in zip(querys, responses):\n",
    "\n",
    "    relevant_docs = get_relevant_docs(query=query)\n",
    "    response = generate_answer(query, relevant_docs)\n",
    "    dataset.append(\n",
    "        {\n",
    "            \"user_input\":query,\n",
    "            \"retrieved_contexts\":relevant_docs,\n",
    "            \"response\":response,\n",
    "            \"reference\":reference\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90eedcbd57dd4429a323ff73e01dc00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_recall': 0.8333, 'context_precision': 0.8056, 'factual_correctness': 0.5525}\n"
     ]
    }
   ],
   "source": [
    "# Evaluerer datasettet\n",
    "\n",
    "evaluation_dataset = EvaluationDataset.from_list(dataset)\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=evaluation_dataset,\n",
    "    metrics=[LLMContextRecall(), ContextPrecision(), FactualCorrectness()],\n",
    "    llm=evaluator_llm\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
